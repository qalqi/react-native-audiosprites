/**
 * Universal player for audio sprites generated by the 'audiosprite' tool.
 * It requires an AudioContext and fetch to be injected.
 */
export class AudioSpritePlayer {
  audioContext: any;
  fetch: any;
  audioBuffer: any | null;
  manifest: any | null;

  constructor({ audioContext, fetch }: { audioContext: any; fetch: any }) {
    if (!audioContext) {
      throw new Error('An AudioContext instance must be provided.');
    }
    if (!fetch) {
      throw new Error('A fetch implementation must be provided.');
    }
    this.audioContext = audioContext;
    this.fetch = fetch;
    this.audioBuffer = null;
    this.manifest = null;
  }

  async load(json: any, audio?: any) {
    try {
      if (typeof json === 'string') {
        const response = await this.fetch(json);
        if (!response.ok) {
          throw new Error(`Failed to fetch manifest: ${response.statusText}`);
        }
        this.manifest = await response.json();

        if (!this.manifest.resources || !this.manifest.spritemap) {
          throw new Error(
            'Invalid audiosprite manifest format. Missing "resources" or "spritemap".'
          );
        }

        // Find the first supported audio file (e.g., .mp3 or .ogg)
        // For simplicity, we just take the first one.
        const audioFileName = this.manifest.resources[0];
        const audioUrl = new URL(audioFileName, response.url).href;

        const audioResponse = await this.fetch(audioUrl);
        if (!audioResponse.ok) {
          throw new Error(
            `Failed to fetch audio file: ${audioResponse.statusText}`
          );
        }

        const arrayBuffer = await audioResponse.arrayBuffer();
        this.audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
      } else {
        this.manifest = json;
        if (!this.manifest.resources || !this.manifest.spritemap) {
          throw new Error(
            'Invalid audiosprite manifest format. Missing "resources" or "spritemap".'
          );
        }

        let arrayBuffer;
        if (typeof audio === 'string') {
          const audioResponse = await this.fetch(audio);
          if (!audioResponse.ok) {
            throw new Error(
              `Failed to fetch audio file: ${audioResponse.statusText}`
            );
          }
          arrayBuffer = await audioResponse.arrayBuffer();
        } else {
          arrayBuffer = audio;
        }
        this.audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
      }
      console.log('Audio sprite loaded successfully.');
    } catch (error) {
      console.error('Failed to load audio sprite:', error);
      throw error; // Re-throw for user to catch
    }
  }

  play(soundName: string) {
    if (!this.audioBuffer || !this.manifest) {
      console.warn('Audio sprite not loaded. Call load() first.');
      return;
    }

    // Resume context if it was suspended (e.g., by browser policy)
    if (this.audioContext.state === 'suspended') {
      this.audioContext.resume();
    }

    // Get the sound from the 'spritemap'
    const sound = this.manifest.spritemap[soundName];
    if (!sound) {
      console.warn(`Sound "${soundName}" not found in spritemap.`);
      return;
    }

    // Calculate duration from start/end times
    const duration = sound.end - sound.start;

    if (duration <= 0) {
      console.warn(`Sound "${soundName}" has invalid duration.`);
      return;
    }

    const source = this.audioContext.createBufferSource();
    source.buffer = this.audioBuffer;

    const gain = this.audioContext.createGain();
    gain.gain.setValueAtTime(1.0, this.audioContext.currentTime);

    source.connect(gain);
    gain.connect(this.audioContext.destination);

    // Use the 'audiosprite' format: start(when, offset, duration)
    source.start(
      0, // Start playing now
      sound.start, // The offset
      duration // The calculated duration
    );
  }

  getManifest() {
    return this.manifest;
  }

  getAudioBuffer() {
    return this.audioBuffer;
  }
}
