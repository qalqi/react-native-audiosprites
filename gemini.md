Task:
Can you update index.tsx and tests according this code?


Based on https://www.npmjs.com/package/audiosprite
 all the code again for audiosprite creator only that works with above library ..
/**
 * Universal player for audio sprites generated by the 'audiosprite' tool.
 * It requires an AudioContext and fetch to be injected.
 */
export class AudioSpritePlayer {
  /**
   * @param {object} options
   * @param {AudioContext} options.audioContext - An instance of AudioContext.
   * @param {function} options.fetch - A fetch function (e.g., window.fetch).
   */
  constructor({ audioContext, fetch }) {
    if (!audioContext) {
      throw new Error('An AudioContext instance must be provided.');
    }
    if (!fetch) {
      throw new Error('A fetch implementation must be provided.');
    }
    this.audioContext = audioContext;
    this.fetch = fetch;
    this.audioBuffer = null;
    this.manifest = null;
  }

  /**
   * Loads the audio sprite and manifest.
   * @param {string} jsonPath - The path to the manifest.json file.
   */
  async load(jsonPath) {
    try {
      const response = await this.fetch(jsonPath);
      if (!response.ok) {
        throw new Error(`Failed to fetch manifest: ${response.statusText}`);
      }
      this.manifest = await response.json();

      if (!this.manifest.resources || !this.manifest.spritemap) {
        throw new Error('Invalid audiosprite manifest format. Missing "resources" or "spritemap".');
      }

      // Find the first supported audio file (e.g., .mp3 or .ogg)
      // For simplicity, we just take the first one.
      const audioFileName = this.manifest.resources[0];
      const audioUrl = new URL(audioFileName, response.url).href;

      const audioResponse = await this.fetch(audioUrl);
      if (!audioResponse.ok) {
        throw new Error(`Failed to fetch audio file: ${audioResponse.statusText}`);
      }
      
      const arrayBuffer = await audioResponse.arrayBuffer();

      this.audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
      console.log('Audio sprite loaded successfully.');
      
    } catch (error) {
      console.error('Failed to load audio sprite:', error);
      throw error; // Re-throw for user to catch
    }
  }

  /**
   * Plays a sound from the sprite.
   * @param {string} soundName - The name of the sound in the 'spritemap'.
   */
  play(soundName) {
    if (!this.audioBuffer || !this.manifest) {
      console.warn('Audio sprite not loaded. Call load() first.');
      return;
    }

    // Resume context if it was suspended (e.g., by browser policy)
    if (this.audioContext.state === 'suspended') {
      this.audioContext.resume();
    }

    // Get the sound from the 'spritemap'
    const sound = this.manifest.spritemap[soundName];
    if (!sound) {
      console.warn(`Sound "${soundName}" not found in spritemap.`);
      return;
    }

    // Calculate duration from start/end times
    const duration = sound.end - sound.start;

    if (duration <= 0) {
        console.warn(`Sound "${soundName}" has invalid duration.`);
        return;
    }

    const source = this.audioContext.createBufferSource();
    source.buffer = this.audioBuffer;
    
    const gain = this.audioContext.createGain();
    gain.gain.setValueAtTime(1.0, this.audioContext.currentTime);

    source.connect(gain);
    gain.connect(this.audioContext.destination);

    // Use the 'audiosprite' format: start(when, offset, duration)
    source.start(
      0, // Start playing now
      sound.start, // The offset
      duration // The calculated duration
    );
  }

  /**
   * @returns {object | null} The loaded manifest.
   */
  getManifest() {
    return this.manifest;
  }

  /**
   * @returns {AudioBuffer | null} The loaded AudioBuffer.
   */
  getAudioBuffer() {
    return this.audioBuffer;
  }
}



const { AudioSpritePlayer } = require('../src');

// --- Mocks ---

// Mock Web Audio API
class MockGainNode {
  constructor(ctx) { this.context = ctx; this.gain = { setValueAtTime: jest.fn() }; }
  connect = jest.fn();
}
class MockBufferSourceNode {
  constructor(ctx) { this.context = ctx; this.buffer = null; }
  connect = jest.fn();
  start = jest.fn();
}
class MockAudioContext {
  constructor() { this.currentTime = 0; this.state = 'running'; }
  createBufferSource = jest.fn(() => new MockBufferSourceNode(this));
  createGain = jest.fn(() => new MockGainNode(this));
  decodeAudioData = jest.fn((buffer, cb) => cb ? cb('mock-decoded-buffer') : Promise.resolve('mock-decoded-buffer'));
  resume = jest.fn().mockResolvedValue();
  destination = 'mock-destination';
}

// Mock fetch
const mockFetch = jest.fn();

// Mock manifest from 'audiosprite'
const MOCK_MANIFEST = {
  resources: ['sprite.mp3', 'sprite.ogg'],
  spritemap: {
    coin: { start: 0.5, end: 1.0, loop: false },
    jump: { start: 1.2, end: 2.0, loop: false },
  },
};

// --- Tests ---

describe('@audiosprites/player (Web)', () => {
  let audioContext;
  let player;

  beforeEach(() => {
    jest.clearAllMocks();
    
    mockFetch.mockImplementation((url) => {
      if (url.endsWith('.json')) {
        return Promise.resolve({
          ok: true,
          url: 'http://localhost/sprite.json',
          json: () => Promise.resolve(MOCK_MANIFEST),
        });
      }
      if (url.endsWith('.mp3') || url.endsWith('.ogg')) {
        return Promise.resolve({
          ok: true,
          url: 'http://localhost/sprite.mp3',
          arrayBuffer: () => Promise.resolve(new ArrayBuffer(8)),
        });
      }
      return Promise.reject(new Error('Unknown URL'));
    });

    audioContext = new MockAudioContext();
    player = new AudioSpritePlayer({
      audioContext: audioContext,
      fetch: mockFetch,
    });
  });

  it('load() should fetch manifest and first resource', async () => {
    await player.load('http://localhost/sprite.json');

    expect(mockFetch).toHaveBeenCalledWith('http://localhost/sprite.json');
    // It should fetch the *first* resource from the "resources" array
    expect(mockFetch).toHaveBeenCalledWith('http://localhost/sprite.mp3');

    expect(audioContext.decodeAudioData).toHaveBeenCalled();
    expect(player.getManifest()).toEqual(MOCK_MANIFEST);
  });
  
  it('load() should throw if manifest format is invalid', async () => {
    mockFetch.mockImplementationOnce(() => Promise.resolve({
        ok: true,
        json: () => Promise.resolve({ invalid: 'format' })
    }));

    await expect(player.load('bad.json')).rejects.toThrow(
      'Invalid audiosprite manifest format'
    );
  });

  it('play() should calculate duration and start source with correct timings', async () => {
    await player.load('http://localhost/sprite.json');
    player.play('jump');

    expect(audioContext.createBufferSource).toHaveBeenCalledTimes(1);
    const mockSource = audioContext.createBufferSource.mock.results[0].value;
    
    // Check the 'audiosprite' format timings
    // sound.start = 1.2, sound.end = 2.0
    // duration = 2.0 - 1.2 = 0.8
    expect(mockSource.start).toHaveBeenCalledWith(
      0,    // when
      1.2,  // offset (from spritemap.jump.start)
      0.8   // duration (calculated from end - start)
    );
  });

  it('play() should allow multiple overlapping sounds', async () => {
    await player.load('http://localhost/sprite.json');
    
    player.play('coin');
    player.play('jump');

    expect(audioContext.createBufferSource).toHaveBeenCalledTimes(2);

    // Check timings for 'coin' (start: 0.5, end: 1.0)
    const source1 = audioContext.createBufferSource.mock.results[0].value;
    expect(source1.start).toHaveBeenCalledWith(0, 0.5, 0.5);

    // Check timings for 'jump' (start: 1.2, end: 2.0)
    const source2 = audioContext.createBufferSource.mock.results[1].value;
    expect(source2.start).toHaveBeenCalledWith(0, 1.2, 0.8);
  });
  
  it('play() should warn if sound is not found in spritemap', async () => {
    const consoleWarnSpy = jest.spyOn(console, 'warn').mockImplementation();
    await player.load('http://localhost/sprite.json');
    player.play('not-a-sound');
    
    expect(consoleWarnSpy).toHaveBeenCalledWith(
      'Sound "not-a-sound" not found in spritemap.'
    );
    consoleWarnSpy.mockRestore();
  });
});


const { AudioSpritePlayer } = require('../src');

// --- Mock react-native-audio-api ---
const mockRNGainNode = {
  gain: { setValueAtTime: jest.fn() },
  connect: jest.fn(),
};
const mockRNBufferSourceNode = {
  buffer: null,
  connect: jest.fn(),
  start: jest.fn(),
};
const mockRNAudioContext = {
  currentTime: 0,
  state: 'running',
  destination: 'mock-rn-destination',
  createBufferSource: jest.fn(() => mockRNBufferSourceNode),
  createGain: jest.fn(() => mockRNGainNode),
  decodeAudioData: jest.fn(() => Promise.resolve('mock-rn-decoded-buffer')),
  resume: jest.fn(() => Promise.resolve()),
};

jest.mock('react-native-audio-api', () => ({
  AudioContext: jest.fn(() => mockRNAudioContext),
}));

// --- Mock fetch ---
const mockFetch = jest.fn();
// Mock manifest from 'audiosprite'
const MOCK_MANIFEST = {
  resources: ['rn-sprite.mp3'],
  spritemap: {
    whoosh: { start: 3.0, end: 4.5, loop: false },
  },
};

// --- Tests ---

describe('@audiosprites/player (React Native)', () => {
  let AudioContext;
  let player;
  let rnAudioContextInstance;

  beforeEach(() => {
    jest.clearAllMocks();

    mockFetch.mockImplementation((url) => {
      if (url.endsWith('.json')) {
        return Promise.resolve({
          ok: true,
          url: 'http://localhost/rn-sprite.json',
          json: () => Promise.resolve(MOCK_MANIFEST),
        });
      }
      if (url.endsWith('.mp3')) {
        return Promise.resolve({
          ok: true,
          url: 'http://localhost/rn-sprite.mp3',
          arrayBuffer: () => Promise.resolve(new ArrayBuffer(8)),
        });
      }
      return Promise.reject(new Error('Unknown URL'));
    });

    AudioContext = require('react-native-audio-api').AudioContext;
    rnAudioContextInstance = new AudioContext();

    player = new AudioSpritePlayer({
      audioContext: rnAudioContextInstance,
      fetch: mockFetch,
    });
  });

  it('should instantiate with the mocked react-native-audio-api context', () => {
    expect(AudioContext).toHaveBeenCalledTimes(1);
    expect(player.audioContext).toBe(mockRNAudioContext);
  });

  it('play() should use RN context and calculate correct duration', async () => {
    await player.load('http://localhost/rn-sprite.json');
    player.play('whoosh');

    // 1. Check RN context was used
    expect(mockRNAudioContext.createBufferSource).toHaveBeenCalledTimes(1);
    expect(mockRNBufferSourceNode.connect).toHaveBeenCalled();

    // 2. **Verify the 'audiosprite' timing for React Native**
    // sound.start = 3.0, sound.end = 4.5
    // duration = 4.5 - 3.0 = 1.5
    expect(mockRNBufferSourceNode.start).toHaveBeenCalledWith(
      0,    // when
      3.0,  // offset (from spritemap.whoosh.start)
      1.5   // duration (calculated from end - start)
    );
  });
});
